# ----------------------------------------------------------------------------
# Title   : Classifier Performance Analysis for Cancer vs. Normal (PE Data)
# Author  : Dory Abelman
# Date    : March 2025
#
# Purpose :
#   • Load predicted class probabilities and metadata for paired-end (PE) samples.
#   • Parse and organize ML output files for multiple feature sets and cohorts.
#   • Compute per‐fold and overall metrics: ROC curves, AUC statistics,
#     sensitivity/specificity (including at 99%, 95%, and 90% specificity), 
#     confusion matrix performance, and Cohen’s kappa across classifiers.
#   • Generate summary tables and visualizations:
#       – ROC curves annotated with mean ± SD AUC
#       – Sensitivity vs. specificity scatterplots
#       – Barplots of sensitivity at high specificity thresholds
#       – Cleveland dot plots of kappa by feature and model
#   • Save results for original and validation cohorts, with detailed CSV exports 
#     for downstream manuscript tables.
# ----------------------------------------------------------------------------


# Load required libraries
library(dplyr)
library(stringr)
library(caret)
library(pROC)
library(ggpubr)
library(gridExtra)
library(zoo)

# Read the actual class probabilities file
actual_class_probs <- readRDS("PCA_results/actual_class_probs.rds")
metadata_df <- readRDS("Metadata df all samples with CN classifier Dec 2024.rds")

## This is the path for the plots for the machine learning outputs generated by the cancer_vs_normal_script
path <- "Final Data Dec 2024/ML_data/PE/Cancer_vs_normal/"

files <- list.files(path = path, pattern = "\\.rds$")
classification_df <- data.frame(file = files, stringsAsFactors = FALSE)

# Extract 'type1' and 'type2' from the file names
classification_df$type1 <- sub(".*outcomes_([^_]+)_vs_.*", "\\1", classification_df$file)
classification_df$type2 <- sub(".*_vs_([^_]+)\\.rds", "\\1", classification_df$file)

# Keep only rows where 'file' contains "outcomes"
classification_df <- classification_df %>%
  filter(grepl("outcomes", file))

# Extract the 'Analysis' column by matching the prefix before the first underscore
classification_df$Analysis <- sub("^CN_classifier_", "", sub("_outcomes_.*", "", classification_df$file))

# To work with for loop
comparisons_classification <- classification_df %>% select(type1, type2)

# Get all types but keep unique 
# Create a function to sort each pair of types
sort_pair <- function(row) {
  return(sort(c(row['type1'], row['type2'])))
}

## Remove the row with analysis "Combined_motif_methylation_PCs_all" since not using it
classification_df <- classification_df %>%
  filter(Analysis != "Combined_motif_methylation_PCs_all")

# Edit to specify what is validation
classification_df <- classification_df %>%
  filter(grepl("outcomes", file)) %>%
  # === CHANGES MADE: Mark each row as "Validation" or "Original" and remove "_validation" ===
  mutate(
    Cohort = ifelse(str_detect(Analysis, "validation"), "Validation", "Original"),
    Analysis = str_remove(Analysis, "_validation")
  )

# Apply the function row-wise and store the sorted pairs in a new dataframe
sorted_comparisons <- t(apply(comparisons_classification, 1, sort_pair))
sorted_comparisons_df <- data.frame(type1 = sorted_comparisons[, 1], type2 = sorted_comparisons[, 2])
#sorted_comparisons_df <- sorted_comparisons_df %>% filter(type2 == "healthy")
# Remove duplicates
unique_comparisons_df <- unique(sorted_comparisons_df)

## Helper function to map raw metric names to pretty labels
get_labels <- function(unique_metrics) {
  label_mapping <- list(
    "Combined_all_features_1pct" = "Combined All Features (1%)",
    "Combined_all_features_5pct" = "Combined All Features (5%)",
    "Combined_motif_methylation_PCs_1pct" = "Combined Motif + Methylation (1%)",
    "Combined_motif_methylation_ratios_PCs_1pct" = "Combined Motif + Methylation + Ratios (1%)",
    "Combined_ratios_methylation_PCs_1pct" = "Combined Ratios + Methylation (1%)",
    "End_motifs" = "End Motifs",
    "Insert_size" = "Insert Size",
    "Methylation" = "Methylation",
    "Nucleosome_peak" = "Nucleosome Peak",
    "Fragment_ratios" = "Fragment Ratio"
  )
  
  sapply(unique_metrics, function(x) {
    if (!is.null(label_mapping[[x]])) label_mapping[[x]] else x
  })
}

## Function to create and save plots for a given comparison & cohort.
create_and_save_plots <- function(data_roc, data_auc, data_cm, data_sens99, suffix, current_cohort, type1, type2, features_summary_all) {
  
  # Ensure mean_auc is numeric and sort by it
  data_auc$mean_auc <- as.numeric(as.character(data_auc$mean_auc))
  data_auc <- data_auc[order(data_auc$mean_auc), ]
  n_rows <- nrow(data_auc)
  data_auc$y_values <- seq(0, 0.3, length.out = n_rows)
  
  ## Define manual color palette.
  my_color_palette <- c(
    "Combined All Features (1%)"          = "#6A3D9A",
    "Combined All Features (5%)"          = "#8B4513",
    "Combined Motif + Methylation (1%)"   = "#32CD32",
    "Combined Motif + Methylation + Ratios (1%)" = "#FFD700",
    "Combined Ratios + Methylation (1%)" = "#FF4500",  # Added a new color (Orange-Red)
    "End Motifs"                          = "#E69F00",
    "Insert Size"                         = "#56B4E9",
    "Methylation"                         = "#CC79A7",
    "Nucleosome Peak"                     = "#0072B2",
    "Fragment Ratio"                      = "#009E73"
  )
  data_roc_plot <- data_roc %>%
    group_by(Metric, fpr) %>%
    summarise(tpr = mean(tpr, na.rm = TRUE),
              sd_tpr = mean(sd_tpr, na.rm = TRUE)) %>%
    ungroup()
  
  ## Create the ROC plot.
  AUC_plot <- ggplot(data_roc_plot, aes(x = fpr, y = tpr, group = Metric, color = Metric)) +
    #   geom_ribbon(aes(ymin = tpr - sd_tpr, ymax = tpr + sd_tpr, fill = Metric), alpha = 0.2) +
    geom_line(aes(group = Metric), size = 1) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(data = data_auc, 
              aes(x = 0.7, y = y_values, label = sprintf("%s = %.3f ± %.3f", Metric, mean_auc, sd_auc), color = Metric), 
              size = 2.5) +
    scale_color_manual(values = my_color_palette) +
    scale_fill_manual(values = my_color_palette) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curves with AUC Statistics") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = "none")
  
  ## Create the performance (confusion matrix) plot.
  CM_plot <- ggplot(data_cm, aes(x = mean_sensitivity, y = mean_specificity, color = Metric)) +
    geom_point(size = 3) +
    geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
    # Horizontal error bars clipped at [0,1]
    geom_errorbarh(aes(
      xmin = pmax(0, mean_sensitivity - sd_sensitivity),  # Prevent going below 0
      xmax = pmin(1, mean_sensitivity + sd_sensitivity),  # Prevent exceeding 1
      y = mean_specificity), 
      height = 0.02, alpha = 0.7) +
    
    # Vertical error bars clipped at [0,1]
    geom_errorbar(aes(
      ymin = pmax(0, mean_specificity - sd_specificity),  # Prevent going below 0
      ymax = pmin(1, mean_specificity + sd_specificity),  # Prevent exceeding 1
      x = mean_sensitivity), 
      width = 0.02, alpha = 0.7) +
    scale_color_manual(values = my_color_palette) +
    xlab("Sensitivity") +
    ylab("Specificity") +
    ggtitle("Performance") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = c(0.5, 0.21)) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    guides(color = guide_legend(ncol = 2))
  
  ## Create the sensitivity at 99% specificity bar plot.
  data_sens99 <- data_sens99 %>% arrange(desc(mean_sens99))
  data_sens99$Metric <- factor(data_sens99$Metric, levels = data_sens99$Metric)
  
  # Create the sensitivity at 99% specificity bar plot with the updated theme
  sens99_plot <- ggplot(data_sens99, aes(x = Metric, y = mean_sens99, fill = Metric)) +
    geom_bar(stat = "identity", width = 0.7, color = NA) +
    geom_errorbar(aes(ymin = mean_sens99 - sd_sens99, ymax = mean_sens99 + sd_sens99), width = 0.2) +
    scale_fill_manual(values = my_color_palette) +
    xlab("Method") +
    ylab("Sensitivity at 99% Specificity") +
    ggtitle("Sensitivity at 99% Specificity by Method") +
    theme(
      plot.title = element_text(hjust = 0.5, size = 13),
      axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      legend.position = "none",
      legend.key = element_rect(fill = "white"),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12),
      strip.background = element_blank(),
      strip.text = element_text(size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),  # rotated & smaller
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 13)
    )
  
  
  
  ## Combine the plots and add a title.
  title_text <- paste0(type1, " vs ", type2, " (", current_cohort, " cohort)")
  ## Arrange the ROC and CM plots in a row
  top_row <- ggarrange(AUC_plot, CM_plot, ncol = 2)
  # final_fig <- ggarrange(top_row, features_table, nrow = 2, heights = c(2, 1))
  final_fig <- top_row
  final_fig <- annotate_figure(final_fig, top = text_grob(title_text, face = "bold", size = 14))
  
  ggsave(file.path(path, paste0("Sens99_plot_", type1, "_vs_", type2, "_", suffix, "_", current_cohort, "2.pdf")), 
         sens99_plot, width = 5, height = 5)
  
  out_file <- file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_", suffix, "_", current_cohort, " combined updated 2.pdf"))
  ggsave(out_file, final_fig, width = 9, height = 5)
}

########################################
## Outer loop: for each unique comparison
########################################
for (i in 1:nrow(unique_comparisons_df)) {
  type1 <- unique_comparisons_df$type1[i]
  type2 <- unique_comparisons_df$type2[i]
  
  pattern_to_search <- paste0("(", type1, "_vs_", type2, "|", type2, "_vs_", type1, ")\\.rds")
  filenames_short <- list.files(path, pattern = pattern_to_search, full.names = FALSE)
  filenames <- list.files(path, pattern = pattern_to_search, full.names = TRUE)
  subset_class_df <- classification_df %>% filter(file %in% filenames_short)
  
  ########################################
  ## Inner loop: Process by cohort
  ########################################
  for (current_cohort in unique(subset_class_df$Cohort)) {
    filtered_class_df <- classification_df %>% filter(file %in% filenames_short, Cohort == current_cohort)
    filtered_filenames_short <- filtered_class_df$file
    filtered_analyses <- filtered_class_df$Analysis
    
    # Initialize overall containers for this cohort.
    data_roc <- data.frame()
    data_auc <- data.frame()
    data_cm  <- data.frame()
    features_summary_all <- data.frame()

    # NEW: container for sensitivity at 99% specificity:
    data_sens99 <- data.frame()
    # NEW: container for sensitivity at 95% specificity:
    data_sens95 <- data.frame()
    # NEW: container for sensitivity at 90% specificity:
    data_sens90 <- data.frame()
    
    # NEW: Initialize container for per-sample classification details.
    classification_details_all <- data.frame()
    
    ########################################
    ## File loop: Process each file
    ########################################
    for (j in seq_along(filenames)) {
      file <- filenames[[j]]
      filename_short <- filenames_short[[j]]
      if (!(filename_short %in% filtered_filenames_short)) next
      
      analysis <- filtered_analyses[filtered_filenames_short == filename_short][1]
      
      ## Read in file and “unwrap” it if necessary.
      data_obj <- readRDS(file)
      data_list <- lapply(data_obj, function(x) {
        if (is.data.frame(x)) {
          list(x)
        } else if (is.list(x) && length(x) == 1 && is.data.frame(x[[1]])) {
          x
        } else if (is.list(x) && length(x) == 1 && is.list(x[[1]]) &&
                   length(x[[1]]) == 1 && is.data.frame(x[[1]][[1]])) {
          x[[1]]
        } else {
          x
        }
      })
      if (!is.list(data_list)) stop("The loaded RDS file is not structured as a list of folds.")
      
      fold_names <- names(data_list)
      if (is.null(fold_names)) fold_names <- paste0("Fold_", seq_along(data_list))
      
      data_list <- lapply(seq_along(data_list), function(i) {
        fold_data <- data_list[[i]]
        if (is.data.frame(fold_data)) {
          fold_data$Fold <- fold_names[i]
          return(fold_data)
        } else if (is.list(fold_data) && length(fold_data) == 1 && is.data.frame(fold_data[[1]])) {
          fold_data[[1]]$Fold <- fold_names[i]
          return(fold_data[[1]])
        } else {
          stop(paste("Unexpected structure in fold", fold_names[i]))
        }
      })
      data <- bind_rows(data_list)
      
      # Rename column if needed.
      if ("Predicted" %in% colnames(data))
        data <- data %>% rename(PredictedClass = Predicted)
      
      # Clean sample names.
      data$sample <- data$sample %>%
        str_remove("_motifs$") %>%
        str_remove("_peak_distance$") %>%
        str_remove("_dedup$")
      
      # If ActualClass is missing, join with actual_class_probs.
      # Remove terminal "_dedup" from actual_class_probs$sample_id
      actual_class_probs <- actual_class_probs %>%
        mutate(sample = str_remove(sample_id, "_dedup$"))
      
      if (!"ActualClass" %in% colnames(data)) {
        data <- data %>% left_join(
          actual_class_probs %>% select(sample, CN_classifier) %>% rename(ActualClass = CN_classifier),
          by = "sample"
        )
      }
      
      data$ActualClass <- factor(data$ActualClass, levels = c(type1, type2))
      data$PredictedClass <- factor(data$PredictedClass, levels = c(type1, type2))
      
      ## Compute the default confusion matrix (for reference).
      cm_default <- confusionMatrix(data$PredictedClass, data$ActualClass)
      cm_default <- data.frame(Metric = analysis,
                               sensitivity = cm_default[["byClass"]][["Sensitivity"]],
                               specificity = cm_default[["byClass"]][["Specificity"]])
      
      ## Create a probability column using dynamic class names.
      # data$prob_cancer <- ifelse(data$PredictedClass == type1, data[[type1]], 1 - data[[type2]])
      data$prob_cancer <- data[[type1]]
      
      
      # >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
      # NEW: Collect per-sample classification details for this file
      classification_details <- data %>%
        dplyr::select(
          sample,
          ActualClass,
          PredictedClass,
          prob_cancer
        ) %>%
        mutate(
          Analysis = analysis,
          File = filename_short,
          Cohort = current_cohort
        )
      
      # Accumulate these details into the container for this cohort
      classification_details_all <- rbind(classification_details_all, classification_details)
      # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
      
      ## ----- Feature Summary Statistics per Fold -----
      features_summary_fold <- data %>%
        group_by(Fold) %>%
        summarise(
          !!paste0("mean_", type1) := mean(.data[[type1]], na.rm = TRUE),
          !!paste0("sd_", type1)   := sd(.data[[type1]], na.rm = TRUE),
          !!paste0("mean_", type2) := mean(.data[[type2]], na.rm = TRUE),
          !!paste0("sd_", type2)   := sd(.data[[type2]], na.rm = TRUE),
          mean_prob_cancer = mean(prob_cancer, na.rm = TRUE),
          sd_prob_cancer   = sd(prob_cancer, na.rm = TRUE)
        ) %>%
        mutate(Analysis = analysis, File = filename_short, Cohort = current_cohort)
      
      features_summary_all <- rbind(features_summary_all, as.data.frame(features_summary_fold))
      
      ## ----- Compute ROC & AUC -----
      data$ActualClass_numeric <- ifelse(data$ActualClass == type2, 0, 1)
      
      auc_per_fold <- data %>% group_by(Fold) %>%
        summarise(auc = if (length(unique(ActualClass)) < 2) NA_real_ else as.numeric(auc(ifelse(ActualClass == type1, 1, 0), prob_cancer)))
      
      mean_auc_val <- mean(auc_per_fold$auc, na.rm = TRUE)
      sd_auc_val <- sd(auc_per_fold$auc, na.rm = TRUE)
      min_auc_val <- min(auc_per_fold$auc, na.rm = TRUE)
      max_auc_val <- max(auc_per_fold$auc, na.rm = TRUE)
      
      auc_df <- data.frame(
        Metric = analysis,
        mean_auc = mean_auc_val,
        sd_auc = sd_auc_val,
        min_auc = min_auc_val,
        max_auc = max_auc_val
      )
      
      ## Compute ROC for each fold.
      roc_list <- lapply(unique(data$Fold), function(fold) {
        fold_data <- data %>% filter(Fold == fold)
        fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
        roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
      })
      common_fpr <- seq(0, 1, length.out = 100)
      tpr_matrix <- sapply(roc_list, function(roc_obj) {
        fold_fpr <- 1 - roc_obj$specificities
        fold_tpr <- roc_obj$sensitivities
        approx(x = fold_fpr, y = fold_tpr, xout = common_fpr, rule = 2)$y
      })
      mean_tpr <- rowMeans(tpr_matrix, na.rm = TRUE)
      sd_tpr <- apply(tpr_matrix, 1, sd, na.rm = TRUE)
      
      # ----- NEW: Compute sensitivity at 99% specificity for each fold.
      sens_at_99_per_fold <- sapply(roc_list, function(roc_obj) {
        # Force a numeric scalar; take the first value if more than one is returned.
        as.numeric(coords(roc_obj, x = 0.99, input = "specificity", ret = "sensitivity", transpose = FALSE))[1]
      })
      
      mean_sens99 <- mean(sens_at_99_per_fold, na.rm = TRUE)
      sd_sens99 <- sd(sens_at_99_per_fold, na.rm = TRUE)
      
      # Save the sensitivity values for this file (i.e. analysis method)
      sens99_df <- data.frame(
        Metric = analysis,
        mean_sens99 = mean_sens99,
        sd_sens99 = sd_sens99
      )
      data_sens99 <- rbind(data_sens99, sens99_df)
      
      # ----- Compute sensitivity at 95% specificity for each fold. -----
      sens_at_95_per_fold <- sapply(roc_list, function(roc_obj) {
        as.numeric(coords(roc_obj,
                          x        = 0.95,
                          input    = "specificity",
                          ret      = "sensitivity",
                          transpose = FALSE))[1]
      })
      mean_sens95 <- mean(sens_at_95_per_fold, na.rm = TRUE)
      sd_sens95   <- sd(sens_at_95_per_fold, na.rm = TRUE)
      
      sens95_df <- data.frame(
        Metric      = analysis,
        mean_sens95 = mean_sens95,
        sd_sens95   = sd_sens95
      )
      data_sens95 <- rbind(data_sens95, sens95_df)
      
      # ----- Compute sensitivity at 90% specificity for each fold. -----
      sens_at_90_per_fold <- sapply(roc_list, function(roc_obj) {
        as.numeric(coords(roc_obj,
                          x        = 0.90,
                          input    = "specificity",
                          ret      = "sensitivity",
                          transpose = FALSE))[1]
      })
      mean_sens90 <- mean(sens_at_90_per_fold, na.rm = TRUE)
      sd_sens90   <- sd(sens_at_90_per_fold, na.rm = TRUE)
      
      sens90_df <- data.frame(
        Metric      = analysis,
        mean_sens90 = mean_sens90,
        sd_sens90   = sd_sens90
      )
      data_sens90 <- rbind(data_sens90, sens90_df)
      
      
      # For a bit more smoothing
      #     window_size <- 5  # Adjust if needed
      #     mean_tpr <- rollmean(rowMeans(tpr_matrix, na.rm = TRUE), k = window_size, fill = NA, align = "center")
      #     sd_tpr <- rollmean(apply(tpr_matrix, 1, sd, na.rm = TRUE), k = window_size, fill = NA, align = "center")
      
      roc_summary_df <- data.frame(
        fpr = common_fpr,
        mean_tpr = mean_tpr,
        sd_tpr = sd_tpr
      )
      
      roc_obj_final <- roc(response = data$ActualClass,
                           predictor = data$prob_cancer,
                           levels = c(type2, type1),  # normal then cancer
                           direction = "<")
      roc_df <- data.frame(
        fpr = 1 - roc_obj_final$specificities,
        tpr = roc_obj_final$sensitivities,
        Metric = analysis
      )
      
      ## ----- Compute Confusion Matrix Metrics per Fold -----
      cm_per_fold <- data %>%
        group_by(Fold) %>%
        do({
          fold_data <- .
          fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
          
          # Check that both classes are present
          if(length(unique(fold_data$ActualClass_numeric)) < 2) {
            return(data.frame(sensitivity = NA, specificity = NA))
          }
          
          # Convert prob_cancer safely, though it appears numeric already.
          fold_data$prob_cancer <- as.numeric(fold_data$prob_cancer)
          
          roc_obj <- roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
          
          # Use unlist() to be extra safe in case coords returns a list
          opt_threshold <- as.numeric(unlist(coords(roc_obj, "best", ret = "threshold", best.method = "youden")))
          
          fold_data$pred_class_opt <- ifelse(fold_data$prob_cancer >= opt_threshold, type1, type2)
          
          cm <- confusionMatrix(
            factor(fold_data$pred_class_opt, levels = c(type1, type2)),
            factor(ifelse(fold_data$ActualClass_numeric == 1, type1, type2), levels = c(type1, type2)),
            positive = type1
          )
          
          
          data.frame(
            sensitivity = cm[["byClass"]][["Sensitivity"]],
            specificity = cm[["byClass"]][["Specificity"]]
          )
        })
      
      
      
      mean_sensitivity <- mean(cm_per_fold$sensitivity, na.rm = TRUE)
      sd_sensitivity <- sd(cm_per_fold$sensitivity, na.rm = TRUE)
      mean_specificity <- mean(cm_per_fold$specificity, na.rm = TRUE)
      sd_specificity <- sd(cm_per_fold$specificity, na.rm = TRUE)
      
      cm_df <- data.frame(
        Metric = analysis,
        mean_sensitivity = mean_sensitivity,
        sd_sensitivity = sd_sensitivity,
        mean_specificity = mean_specificity,
        sd_specificity = sd_specificity
      )
      
      ## Append per-file results to overall containers.
      data_auc <- rbind(data_auc, auc_df)
      data_cm <- rbind(data_cm, cm_df)
      data_roc <- rbind(data_roc, roc_df)
      
    }  # End file loop for this cohort.
    
    ## Map raw metric names to pretty labels.
    unique_metrics <- unique(data_roc$Metric)
    data_roc$Metric <- factor(data_roc$Metric, levels = unique_metrics, labels = get_labels(unique_metrics))
    data_auc$Metric <- factor(data_auc$Metric, levels = unique_metrics, labels = get_labels(unique_metrics))
    data_cm$Metric <- factor(data_cm$Metric, levels = unique_metrics, labels = get_labels(unique_metrics))
    data_sens99$Metric <- factor(data_sens99$Metric, levels = unique_metrics, labels = get_labels(unique_metrics))
    
    suffix <- ifelse(grepl("PC", filtered_class_df$Analysis[1]), "PCA", "all_features")
    
    ## Compute summary statistics for AUC (across files) for this cohort.
    data_auc_summary <- data_auc %>%
      group_by(Metric) %>%
      summarise(
        mean_auc = mean(as.numeric(mean_auc), na.rm = TRUE),
        sd_auc = sd(as.numeric(mean_auc), na.rm = TRUE),
        min_auc = min(as.numeric(mean_auc), na.rm = TRUE),
        max_auc = max(as.numeric(mean_auc), na.rm = TRUE)
      ) %>%
      mutate(
        auc_text = sprintf("%s = %.3f ± %.3f (%.3f - %.3f)", Metric, mean_auc, sd_auc, min_auc, max_auc)
      )
    
    cat("\n--- AUC Summary Statistics for Cohort:", current_cohort, "---\n")
    print(data_auc_summary)
    
    auc_output_file <- file.path(path, paste0("AUC_summary_", current_cohort, ".csv"))
    write.csv(data_auc_summary, auc_output_file, row.names = FALSE)
    
    features_output_file <- file.path(path, paste0("features_summary_", type1, "_vs_", type2, "_", current_cohort, ".csv"))
    write.csv(features_summary_all, features_output_file, row.names = FALSE)
    
    sens99_summary <- data_sens99 %>%
      mutate(
        sens_text = sprintf("%s: Sensitivity=%.3f ± %.3f", Metric, mean_sens99, sd_sens99)
      )
    sens99_output_file <- file.path(path, paste0("Sens99_summary_", type1, "_vs_", type2, "_", current_cohort, ".csv"))
    write.csv(sens99_summary, sens99_output_file, row.names = FALSE)
    
    ## NEW: Sens95 summary
    sens95_summary      <- data_sens95 %>%
      mutate(sens95_text = sprintf("%s: Sensitivity=%.3f ± %.3f",
                                   Metric, mean_sens95, sd_sens95))
    sens95_output_file  <- file.path(path,
                                     paste0("Sens95_summary_", type1, "_vs_", type2, "_", current_cohort, ".csv"))
    write.csv(sens95_summary, sens95_output_file, row.names = FALSE)
    
    ## NEW: Sens90 summary
    sens90_summary     <- data_sens90 %>%
      mutate(sens90_text = sprintf("%s: Sensitivity=%.3f ± %.3f",
                                   Metric, mean_sens90, sd_sens90))
    sens90_output_file <- file.path(path,
                                    paste0("Sens90_summary_", type1, "_vs_", type2, "_", current_cohort, ".csv"))
    write.csv(sens90_summary, sens90_output_file, row.names = FALSE)
    
    
    # AFTER file loop, we can now export the classification_details_all for this cohort
    classification_details_output_file <- file.path(
      path,
      paste0("classification_details_", type1, "_vs_", type2, "_", current_cohort, ".csv")
    )
    write.csv(classification_details_all, classification_details_output_file, row.names = FALSE)
    
    create_and_save_plots(data_roc, data_auc, data_cm, data_sens99, suffix, current_cohort, type1, type2, features_summary_all)
    
  }  # End inner cohort loop.
  
}  # End outer comparison loop.








####### Now go line by line for validation cohort in case errors to split the groups 
# ---------------------------
# SETUP & PRELIMINARY FILTERING
# ---------------------------

# Filter classification_df to keep only files with "outcomes"
classification_df <- classification_df %>% filter(grepl("outcomes", file))

# Extract the Analysis column (prefix before the first underscore)
classification_df$Analysis <- sub("^CN_classifier_", "", sub("_outcomes_.*", "", classification_df$file))

# Remove the row with analysis "Combined_motif_methylation_PCs_all"
classification_df <- classification_df %>% filter(Analysis != "Combined_motif_methylation_PCs_all")

# Mark cohort: if Analysis contains "validation", label as Validation, otherwise Original.
classification_df <- classification_df %>% 
  mutate(
    Cohort = ifelse(str_detect(Analysis, "validation"), "Validation", "Original"),
    Analysis = str_remove(Analysis, "_validation")
  )

# Create unique comparisons (here we use type1 and type2 from the file names)
comparisons_classification <- classification_df %>% select(type1, type2)
sorted_comparisons <- t(apply(comparisons_classification, 1, function(row) sort(c(row['type1'], row['type2']))))
unique_comparisons_df <- unique(data.frame(type1 = sorted_comparisons[,1], type2 = sorted_comparisons[,2]))

# ---------------------------
# DEFINE SAMPLE GROUPS FOR VALIDATION
# ---------------------------

# List samples in the LFS cohort, previvor and survival 
lfs_samples <- metadata_df %>% 
  filter(grepl("TCGE-CFMe-LFS", project_id) & 
           cancer_type_corrected_updated %in% c("lfs_previvor", "lfs_survivor")) %>% 
  select(sample) %>% 
  unique()

# List healthy samples in the HCC cohort
healthy_hcc_samples <- metadata_df %>% 
  filter(project_id == "TCGE-CFMe-HCC" & cancer_type_corrected_updated == "healthy") %>% 
  select(sample) %>% unique()

# group2_samples: union of LFS samples and healthy HCC samples
group2_samples <- union(lfs_samples$sample, healthy_hcc_samples$sample)

# group1_samples: all validation samples minus LFS samples
group1_samples <- setdiff(unique(actual_class_probs$sample), lfs_samples$sample)

# ---------------------------
# PROCESS VALIDATION COHORT FOR THE FIRST COMPARISON (Line-by-Line)
# ---------------------------

# Select the first unique comparison for processing
type1 <- unique_comparisons_df$type1[1]
type2 <- unique_comparisons_df$type2[1]

# Filter classification_df to only Validation files for this comparison
# Construct the regex pattern
regex_pattern <- paste0(type1, "_vs_", type2, "|", type2, "_vs_", type1)
print(regex_pattern)  # This prints the regex pattern to the console

# Filter the classification_df based on the cohort and the regex pattern in the 'file' column
val_df <- classification_df %>% 
  filter(Cohort == "Validation" & grepl(regex_pattern, file))

# Print the resulting data frame
print(val_df)


#val_df <- classification_df %>% filter(Cohort == "Validation" & grepl(paste0(type1, "_vs_", type2, "|", type2, "_vs_", type1), file))
# Get the list of files (short names and full paths)
filenames_short <- val_df$file
filenames <- list.files(path, pattern = paste0("(", type1, "_vs_", type2, "|", type2, "_vs_", type1, ")\\.rds"), full.names = TRUE)
filtered_analyses <- val_df$Analysis

# ---------------------------
# PROCESS GROUP1 (Validation samples NOT in LFS)
# ---------------------------

# Initialize empty containers for group1 results
val_data_roc_group1 <- data.frame()
val_data_auc_group1 <- data.frame()
val_data_cm_group1 <- data.frame()
val_data_sens99_group1 <- data.frame()
val_features_summary_group1 <- data.frame()
val_classification_details_group1 <- data.frame()

val_data_sens95_group1 <- data.frame()
val_data_sens90_group1 <- data.frame()


for (j in seq_along(filenames)) {
  file <- filenames[[j]]
  # Only proceed if the file's short name is in our filtered list
  if (!(basename(file) %in% filenames_short)) next
  
  analysis <- filtered_analyses[filenames_short == basename(file)][1]
  
  # Read in the file and "unwrap" it
  data_obj <- readRDS(file)
  data_list <- lapply(data_obj, function(x) {
    if (is.data.frame(x)) {
      list(x)
    } else if (is.list(x) && length(x)==1 && is.data.frame(x[[1]])) {
      x
    } else if (is.list(x) && length(x)==1 && is.list(x[[1]]) && length(x[[1]])==1 && is.data.frame(x[[1]][[1]])) {
      x[[1]]
    } else {
      x
    }
  })
  if (!is.list(data_list)) stop("File not structured as list of folds.")
  fold_names <- names(data_list)
  if (is.null(fold_names)) fold_names <- paste0("Fold_", seq_along(data_list))
  data_list <- lapply(seq_along(data_list), function(i) {
    fold_data <- data_list[[i]]
    if (is.data.frame(fold_data)) {
      fold_data$Fold <- fold_names[i]
      return(fold_data)
    } else if (is.list(fold_data) && length(fold_data)==1 && is.data.frame(fold_data[[1]])) {
      fold_data[[1]]$Fold <- fold_names[i]
      return(fold_data[[1]])
    } else {
      stop(paste("Unexpected structure in fold", fold_names[i]))
    }
  })
  data <- bind_rows(data_list)
  
  # Rename column if needed
  if ("Predicted" %in% colnames(data)) {
    data <- data %>% rename(PredictedClass = Predicted)
  }
  
  # Clean sample names
  data$sample <- data$sample %>% str_remove("_motifs$") %>% str_remove("_peak_distance$") %>% str_remove("_dedup$")
  
  # Join with actual_class_probs if ActualClass is missing
  actual_class_probs <- actual_class_probs %>% mutate(sample = str_remove(sample_id, "_dedup$"))
  if (!"ActualClass" %in% colnames(data)) {
    data <- data %>% left_join(actual_class_probs %>% select(sample, CN_classifier) %>% rename(ActualClass = CN_classifier), by = "sample")
  }
  
  # Set factor levels for classes
  data$ActualClass <- factor(data$ActualClass, levels = c(type1, type2))
  data$PredictedClass <- factor(data$PredictedClass, levels = c(type1, type2))
  
  # Subset to group1 samples (Validation samples NOT in LFS)
  data <- data %>% filter(sample %in% group1_samples)
  if(nrow(data) == 0) next  # skip file if no group1 samples remain
  
  # Create probability column
  #data$prob_cancer <- ifelse(data$PredictedClass == type1, data[[type1]], 1 - data[[type2]])
  data$prob_cancer <- data[[type1]]
  
  # Collect per-sample classification details
  classification_details <- data %>% select(sample, ActualClass, PredictedClass, prob_cancer) %>%
    mutate(Analysis = analysis, File = basename(file), Cohort = "Validation")
  val_classification_details_group1 <- rbind(val_classification_details_group1, classification_details)
  
  # Feature summary per fold
  features_summary_fold <- data %>% group_by(Fold) %>%
    summarise(
      !!paste0("mean_", type1) := mean(.data[[type1]], na.rm = TRUE),
      !!paste0("sd_", type1)   := sd(.data[[type1]], na.rm = TRUE),
      !!paste0("mean_", type2) := mean(.data[[type2]], na.rm = TRUE),
      !!paste0("sd_", type2)   := sd(.data[[type2]], na.rm = TRUE),
      mean_prob_cancer = mean(prob_cancer, na.rm = TRUE),
      sd_prob_cancer   = sd(prob_cancer, na.rm = TRUE)
    ) %>% mutate(Analysis = analysis, File = basename(file), Cohort = "Validation")
  val_features_summary_group1 <- rbind(val_features_summary_group1, as.data.frame(features_summary_fold))
  
  # Compute ROC & AUC per fold
 # data$ActualClass_numeric <- ifelse(data$ActualClass == type2, 0, 1)
  data$ActualClass_numeric <- ifelse(data$ActualClass == type1, 1, 0)
  auc_per_fold <- data %>% group_by(Fold) %>%
    summarise(auc = if (length(unique(ActualClass)) < 2) NA_real_ else as.numeric(auc(ifelse(ActualClass == type1, 1, 0), prob_cancer)))
  
  mean_auc_val <- mean(auc_per_fold$auc, na.rm = TRUE)
  sd_auc_val <- sd(auc_per_fold$auc, na.rm = TRUE)
  min_auc_val <- min(auc_per_fold$auc, na.rm = TRUE)
  max_auc_val <- max(auc_per_fold$auc, na.rm = TRUE)
  auc_df <- data.frame(Metric = analysis, mean_auc = mean_auc_val, sd_auc = sd_auc_val,
                       min_auc = min_auc_val, max_auc = max_auc_val)
  val_data_auc_group1 <- rbind(val_data_auc_group1, auc_df)
  
  # Compute ROC for each fold
  roc_list <- lapply(unique(data$Fold), function(fold) {
    fold_data <- data %>% filter(Fold == fold)
    fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
    if (length(unique(fold_data$ActualClass_numeric)) < 2) return(NULL)
    roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
  })
  roc_list <- roc_list[!sapply(roc_list, is.null)]
  common_fpr <- seq(0, 1, length.out = 100)
  if (length(roc_list) == 0) {
    mean_tpr <- rep(NA, length(common_fpr))
    sd_tpr <- rep(NA, length(common_fpr))
  } else {
    tpr_matrix <- vapply(roc_list, function(roc_obj) {
      fold_fpr <- 1 - roc_obj$specificities
      fold_tpr <- roc_obj$sensitivities
      as.numeric(approx(x = fold_fpr, y = fold_tpr, xout = common_fpr, rule = 2)$y)
    }, FUN.VALUE = numeric(length(common_fpr)))
    if (is.null(dim(tpr_matrix))) tpr_matrix <- matrix(tpr_matrix, ncol = 1)
    mean_tpr <- rowMeans(tpr_matrix, na.rm = TRUE)
    sd_tpr <- apply(tpr_matrix, 1, sd, na.rm = TRUE)
  }
  roc_obj_final <- roc(response = data$ActualClass,
                       predictor = data$prob_cancer,
                       levels = c(type2, type1),  # normal then cancer
                       direction = "<")
  roc_df <- data.frame(fpr = 1 - roc_obj_final$specificities,
                       tpr = roc_obj_final$sensitivities,
                       Metric = analysis)
  val_data_roc_group1 <- rbind(val_data_roc_group1, roc_df)
  
  # Compute sensitivity at 99% specificity per fold
  sens_at_99_per_fold <- sapply(roc_list, function(roc_obj) {
    as.numeric(coords(roc_obj, x = 0.99, input = "specificity", ret = "sensitivity", transpose = FALSE))[1]
  })
  mean_sens99 <- mean(sens_at_99_per_fold, na.rm = TRUE)
  sd_sens99 <- sd(sens_at_99_per_fold, na.rm = TRUE)
  sens99_df <- data.frame(Metric = analysis, mean_sens99 = mean_sens99, sd_sens99 = sd_sens99)
  val_data_sens99_group1 <- rbind(val_data_sens99_group1, sens99_df)
  
  # ----- Compute sensitivity at 95% specificity -----
  sens_at_95_per_fold <- sapply(roc_list, function(roc_obj) {
    as.numeric(coords(roc_obj,
                      x         = 0.95,
                      input     = "specificity",
                      ret       = "sensitivity",
                      transpose = FALSE))[1]
  })
  mean_sens95 <- mean(sens_at_95_per_fold, na.rm = TRUE)
  sd_sens95   <- sd(sens_at_95_per_fold, na.rm = TRUE)
  sens95_df   <- data.frame(Metric = analysis,
                            mean_sens95 = mean_sens95,
                            sd_sens95   = sd_sens95)
  val_data_sens95_group1 <- rbind(val_data_sens95_group1, sens95_df)
  
  # ----- Compute sensitivity at 90% specificity -----
  sens_at_90_per_fold <- sapply(roc_list, function(roc_obj) {
    as.numeric(coords(roc_obj,
                      x         = 0.90,
                      input     = "specificity",
                      ret       = "sensitivity",
                      transpose = FALSE))[1]
  })
  mean_sens90 <- mean(sens_at_90_per_fold, na.rm = TRUE)
  sd_sens90   <- sd(sens_at_90_per_fold, na.rm = TRUE)
  sens90_df   <- data.frame(Metric = analysis,
                            mean_sens90 = mean_sens90,
                            sd_sens90   = sd_sens90)
  val_data_sens90_group1 <- rbind(val_data_sens90_group1, sens90_df)
  
  # Compute confusion matrix metrics per fold
  cm_per_fold <- data %>% group_by(Fold) %>%
    do({
      fold_data <- .
      fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
      if (length(unique(fold_data$ActualClass_numeric)) < 2) {
        return(data.frame(sensitivity = NA, specificity = NA))
      }
      fold_data$prob_cancer <- as.numeric(fold_data$prob_cancer)
      roc_obj <- roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
      opt_threshold <- as.numeric(unlist(coords(roc_obj, "best", ret = "threshold", best.method = "youden")))
      fold_data$pred_class_opt <- ifelse(fold_data$prob_cancer >= opt_threshold, type1, type2)
      cm <- confusionMatrix(
        factor(fold_data$pred_class_opt, levels = c(type1, type2)),
        factor(ifelse(fold_data$ActualClass_numeric == 1, type1, type2), levels = c(type1, type2)),
        positive = type1
      )
      
      data.frame(sensitivity = cm[["byClass"]][["Sensitivity"]],
                 specificity = cm[["byClass"]][["Specificity"]])
    })
  mean_sensitivity <- mean(cm_per_fold$sensitivity, na.rm = TRUE)
  sd_sensitivity <- sd(cm_per_fold$sensitivity, na.rm = TRUE)
  mean_specificity <- mean(cm_per_fold$specificity, na.rm = TRUE)
  sd_specificity <- sd(cm_per_fold$specificity, na.rm = TRUE)
  cm_df <- data.frame(Metric = analysis, mean_sensitivity = mean_sensitivity,
                      sd_sensitivity = sd_sensitivity, mean_specificity = mean_specificity,
                      sd_specificity = sd_specificity)
  val_data_cm_group1 <- rbind(val_data_cm_group1, cm_df)
  
}  # End for loop over files for group1

# ---------------------------
# PROCESS GROUP2 (Validation samples in group2_samples)
# ---------------------------

# Initialize containers for group2 results
val_data_roc_group2 <- data.frame()
val_data_auc_group2 <- data.frame()
val_data_cm_group2 <- data.frame()
val_data_sens99_group2 <- data.frame()
val_features_summary_group2 <- data.frame()
val_classification_details_group2 <- data.frame()

val_data_sens95_group2 <- data.frame()
val_data_sens90_group2 <- data.frame()

for (j in seq_along(filenames)) {
  file <- filenames[[j]]
  if (!(basename(file) %in% filenames_short)) next
  analysis <- filtered_analyses[filenames_short == basename(file)][1]
  
  data_obj <- readRDS(file)
  data_list <- lapply(data_obj, function(x) {
    if (is.data.frame(x)) { list(x) }
    else if (is.list(x) && length(x)==1 && is.data.frame(x[[1]])) { x }
    else if (is.list(x) && length(x)==1 && is.list(x[[1]]) && length(x[[1]])==1 && is.data.frame(x[[1]][[1]])) { x[[1]] }
    else { x }
  })
  if (!is.list(data_list)) stop("Not structured as list of folds.")
  fold_names <- names(data_list)
  if (is.null(fold_names)) fold_names <- paste0("Fold_", seq_along(data_list))
  data_list <- lapply(seq_along(data_list), function(i) {
    fold_data <- data_list[[i]]
    if (is.data.frame(fold_data)) {
      fold_data$Fold <- fold_names[i]
      return(fold_data)
    } else if (is.list(fold_data) && length(fold_data)==1 && is.data.frame(fold_data[[1]])) {
      fold_data[[1]]$Fold <- fold_names[i]
      return(fold_data[[1]])
    } else {
      stop(paste("Unexpected structure in fold", fold_names[i]))
    }
  })
  data <- bind_rows(data_list)
  
  if ("Predicted" %in% colnames(data)) {
    data <- data %>% rename(PredictedClass = Predicted)
  }
  
  data$sample <- data$sample %>% str_remove("_motifs$") %>% str_remove("_peak_distance$") %>% str_remove("_dedup$")
  
  actual_class_probs <- actual_class_probs %>% mutate(sample = str_remove(sample_id, "_dedup$"))
  if (!"ActualClass" %in% colnames(data)) {
    data <- data %>% left_join(actual_class_probs %>% select(sample, CN_classifier) %>% rename(ActualClass = CN_classifier), by = "sample")
  }
  
  data$ActualClass <- factor(data$ActualClass, levels = c(type1, type2))
  data$PredictedClass <- factor(data$PredictedClass, levels = c(type1, type2))
  
  # Subset to group2 samples (Validation samples in group2_samples)
  data <- data %>% filter(sample %in% group2_samples)
  if(nrow(data)==0) next
  
  data$prob_cancer <- ifelse(data$PredictedClass == type1, data[[type1]], 1 - data[[type2]])
  
  classification_details <- data %>% select(sample, ActualClass, PredictedClass, prob_cancer) %>%
    mutate(Analysis = analysis, File = basename(file), Cohort = "Validation")
  val_classification_details_group2 <- rbind(val_classification_details_group2, classification_details)
  
  features_summary_fold <- data %>% group_by(Fold) %>%
    summarise(
      !!paste0("mean_", type1) := mean(.data[[type1]], na.rm = TRUE),
      !!paste0("sd_", type1)   := sd(.data[[type1]], na.rm = TRUE),
      !!paste0("mean_", type2) := mean(.data[[type2]], na.rm = TRUE),
      !!paste0("sd_", type2)   := sd(.data[[type2]], na.rm = TRUE),
      mean_prob_cancer = mean(prob_cancer, na.rm = TRUE),
      sd_prob_cancer   = sd(prob_cancer, na.rm = TRUE)
    ) %>% mutate(Analysis = analysis, File = basename(file), Cohort = "Validation")
  val_features_summary_group2 <- rbind(val_features_summary_group2, as.data.frame(features_summary_fold))
  
  data$ActualClass_numeric <- ifelse(data$ActualClass == type2, 0, 1)
  auc_per_fold <- data %>% group_by(Fold) %>%
    summarise(auc = if (length(unique(ActualClass)) < 2) NA_real_ else as.numeric(auc(ifelse(ActualClass == type1, 1, 0), prob_cancer)))
  
  mean_auc_val <- mean(auc_per_fold$auc, na.rm = TRUE)
  sd_auc_val <- sd(auc_per_fold$auc, na.rm = TRUE)
  min_auc_val <- min(auc_per_fold$auc, na.rm = TRUE)
  max_auc_val <- max(auc_per_fold$auc, na.rm = TRUE)
  auc_df <- data.frame(Metric = analysis, mean_auc = mean_auc_val, sd_auc = sd_auc_val,
                       min_auc = min_auc_val, max_auc = max_auc_val)
  val_data_auc_group2 <- rbind(val_data_auc_group2, auc_df)
  
  roc_list <- lapply(unique(data$Fold), function(fold) {
    fold_data <- data %>% filter(Fold == fold)
    fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
    if(length(unique(fold_data$ActualClass_numeric)) < 2) return(NULL)
    roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
  })
  roc_list <- roc_list[!sapply(roc_list, is.null)]
  common_fpr <- seq(0, 1, length.out = 100)
  if(length(roc_list) == 0){
    mean_tpr <- rep(NA, length(common_fpr))
    sd_tpr <- rep(NA, length(common_fpr))
  } else {
    tpr_matrix <- vapply(roc_list, function(roc_obj){
      fold_fpr <- 1 - roc_obj$specificities
      fold_tpr <- roc_obj$sensitivities
      as.numeric(approx(x = fold_fpr, y = fold_tpr, xout = common_fpr, rule = 2)$y)
    }, FUN.VALUE = numeric(length(common_fpr)))
    if(is.null(dim(tpr_matrix))) tpr_matrix <- matrix(tpr_matrix, ncol = 1)
    mean_tpr <- rowMeans(tpr_matrix, na.rm = TRUE)
    sd_tpr <- apply(tpr_matrix, 1, sd, na.rm = TRUE)
  }
  roc_obj_final <- roc(response = data$ActualClass,
                       predictor = data$prob_cancer,
                       levels = c(type2, type1),  # normal then cancer
                       direction = "<")
  roc_df <- data.frame(fpr = 1 - roc_obj_final$specificities,
                       tpr = roc_obj_final$sensitivities,
                       Metric = analysis)
  val_data_roc_group2 <- rbind(val_data_roc_group2, roc_df)
  
  sens_at_99_per_fold <- sapply(roc_list, function(roc_obj) {
    as.numeric(coords(roc_obj, x = 0.99, input = "specificity", ret = "sensitivity", transpose = FALSE))[1]
  })
  mean_sens99 <- mean(sens_at_99_per_fold, na.rm = TRUE)
  sd_sens99 <- sd(sens_at_99_per_fold, na.rm = TRUE)
  sens99_df <- data.frame(Metric = analysis, mean_sens99 = mean_sens99, sd_sens99 = sd_sens99)
  val_data_sens99_group2 <- rbind(val_data_sens99_group2, sens99_df)
  
  cm_per_fold <- data %>% group_by(Fold) %>%
    do({
      fold_data <- .
      fold_data$ActualClass_numeric <- ifelse(fold_data$ActualClass == type2, 0, 1)
      if(length(unique(fold_data$ActualClass_numeric)) < 2) {
        return(data.frame(sensitivity = NA, specificity = NA))
      }
      fold_data$prob_cancer <- as.numeric(fold_data$prob_cancer)
      roc_obj <- roc(fold_data$ActualClass_numeric, fold_data$prob_cancer)
      opt_threshold <- as.numeric(unlist(coords(roc_obj, "best", ret = "threshold", best.method = "youden")))
      fold_data$pred_class_opt <- ifelse(fold_data$prob_cancer >= opt_threshold, type1, type2)
      cm <- confusionMatrix(
        factor(fold_data$pred_class_opt, levels = c(type1, type2)),
        factor(ifelse(fold_data$ActualClass_numeric == 1, type1, type2), levels = c(type1, type2)),
        positive = type1
      )
      
      data.frame(sensitivity = cm[["byClass"]][["Sensitivity"]],
                 specificity = cm[["byClass"]][["Specificity"]])
    })
  mean_sensitivity <- mean(cm_per_fold$sensitivity, na.rm = TRUE)
  sd_sensitivity <- sd(cm_per_fold$sensitivity, na.rm = TRUE)
  mean_specificity <- mean(cm_per_fold$specificity, na.rm = TRUE)
  sd_specificity <- sd(cm_per_fold$specificity, na.rm = TRUE)
  cm_df <- data.frame(Metric = analysis, mean_sensitivity = mean_sensitivity,
                      sd_sensitivity = sd_sensitivity, mean_specificity = mean_specificity,
                      sd_specificity = sd_specificity)
  val_data_cm_group2 <- rbind(val_data_cm_group2, cm_df)
  
}  # End for loop for group2

# ---------------------------
# PRINT RESULTS FOR DEBUGGING
# ---------------------------
print("Group1 AUC:")
print(val_data_auc_group1)
print("Group2 AUC:")
print(val_data_auc_group2)
print("Group1 ROC data:")
print(val_data_roc_group1)
print("Group2 ROC data:")
print(val_data_roc_group2)
print("Group1 Confusion Metrics:")
print(val_data_cm_group1)
print("Group2 Confusion Metrics:")
print(val_data_cm_group2)
print("Group1 Sens99:")
print(val_data_sens99_group1)
print("Group2 Sens99:")
print(val_data_sens99_group2)


##############################
# GENERATE PLOTS FOR EACH GROUP
##############################

# Update Metric labels for Group1 to match the color scale
unique_metrics_group1 <- unique(val_data_auc_group1$Metric)
val_data_auc_group1$Metric <- factor(val_data_auc_group1$Metric, levels = unique_metrics_group1, labels = get_labels(unique_metrics_group1))
val_data_cm_group1$Metric <- factor(val_data_cm_group1$Metric, levels = unique_metrics_group1, labels = get_labels(unique_metrics_group1))
val_data_sens99_group1$Metric <- factor(val_data_sens99_group1$Metric, levels = unique_metrics_group1, labels = get_labels(unique_metrics_group1))
val_data_roc_group1$Metric <- factor(val_data_roc_group1$Metric, levels = unique_metrics_group1, labels = get_labels(unique_metrics_group1))

# ---- Group1 Plots ----
{
  # Process AUC data
  val_data_auc_group1$mean_auc <- as.numeric(as.character(val_data_auc_group1$mean_auc))
  val_data_auc_group1 <- val_data_auc_group1[order(val_data_auc_group1$mean_auc), ]
  n_rows <- nrow(val_data_auc_group1)
  val_data_auc_group1$y_values <- seq(0, 0.3, length.out = n_rows)
  
  my_color_palette <- c(
    "Combined All Features (1%)"          = "#6A3D9A",
    "Combined All Features (5%)"          = "#8B4513",
    "Combined Motif + Methylation (1%)"   = "#32CD32",
    "Combined Motif + Methylation + Ratios (1%)" = "#FFD700",
    "Combined Ratios + Methylation (1%)" = "#FF4500",
    "End Motifs"                          = "#E69F00",
    "Insert Size"                         = "#56B4E9",
    "Methylation"                         = "#CC79A7",
    "Nucleosome Peak"                     = "#0072B2",
    "Fragment Ratio"                      = "#009E73"
  )
  
  data_roc_plot <- val_data_roc_group1 %>%
    group_by(Metric, fpr) %>%
    summarise(tpr = mean(tpr, na.rm = TRUE),
              sd_tpr = mean(sd_tpr, na.rm = TRUE)) %>%
    ungroup()
  
  AUC_plot_group1 <- ggplot(data_roc_plot, aes(x = fpr, y = tpr, group = Metric, color = Metric)) +
    geom_line(aes(group = Metric), size = 1) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(data = val_data_auc_group1, 
              aes(x = 0.7, y = y_values, label = sprintf("%s = %.3f ± %.3f", Metric, mean_auc, sd_auc), color = Metric), 
              size = 2.5) +
    scale_color_manual(values = my_color_palette) +
    scale_fill_manual(values = my_color_palette) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curves with AUC Statistics") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = "none")
  
  CM_plot_group1 <- ggplot(val_data_cm_group1, aes(x = mean_sensitivity, y = mean_specificity, color = Metric)) +
    geom_point(size = 3) +
    geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_errorbarh(aes(
      xmin = pmax(0, mean_sensitivity - sd_sensitivity),
      xmax = pmin(1, mean_sensitivity + sd_sensitivity),
      y = mean_specificity), 
      height = 0.02, alpha = 0.7) +
    geom_errorbar(aes(
      ymin = pmax(0, mean_specificity - sd_specificity),
      ymax = pmin(1, mean_specificity + sd_specificity),
      x = mean_sensitivity), 
      width = 0.02, alpha = 0.7) +
    scale_color_manual(values = my_color_palette) +
    xlab("Sensitivity") +
    ylab("Specificity") +
    ggtitle("Performance") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = c(0.5, 0.21)) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    guides(color = guide_legend(ncol = 2))
  
  val_data_sens99_group1 <- val_data_sens99_group1 %>% arrange(desc(mean_sens99))
  val_data_sens99_group1$Metric <- factor(val_data_sens99_group1$Metric, levels = val_data_sens99_group1$Metric)
  
  sens99_plot_group1 <- ggplot(val_data_sens99_group1, aes(x = Metric, y = mean_sens99, fill = Metric)) +
    geom_bar(stat = "identity", width = 0.7, color = NA) +
    geom_errorbar(aes(ymin = mean_sens99 - sd_sens99, ymax = mean_sens99 + sd_sens99), width = 0.2) +
    scale_fill_manual(values = my_color_palette) +
    xlab("Method") +
    ylab("Sensitivity at 99% Specificity") +
    ggtitle("Sensitivity at 99% Specificity by Method") +
    scale_y_continuous(limits = c(0, 1)) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 13),
      axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      legend.position = "none",
      legend.key = element_rect(fill = "white"),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12),
      strip.background = element_blank(),
      strip.text = element_text(size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 13)
    )
  
  top_row_group1 <- ggarrange(AUC_plot_group1, CM_plot_group1, ncol = 2)
  final_fig_group1 <- annotate_figure(top_row_group1, top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group1)"), face = "bold", size = 14))
  
  ggsave(file.path(path, paste0("Sens99_plot_", type1, "_vs_", type2, "_Group1.pdf")), 
         sens99_plot_group1, width = 5, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group1.pdf")),
         final_fig_group1, width = 9, height = 5)
}

# ---- Group2 Plots ----
# Update Metric labels for Group2 to match the color scale
unique_metrics_group2 <- unique(val_data_auc_group2$Metric)
val_data_auc_group2$Metric <- factor(val_data_auc_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
val_data_cm_group2$Metric <- factor(val_data_cm_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
val_data_sens99_group2$Metric <- factor(val_data_sens99_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
val_data_roc_group2$Metric <- factor(val_data_roc_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))

{
  val_data_auc_group2$mean_auc <- as.numeric(as.character(val_data_auc_group2$mean_auc))
  val_data_auc_group2 <- val_data_auc_group2[order(val_data_auc_group2$mean_auc), ]
  n_rows <- nrow(val_data_auc_group2)
  val_data_auc_group2$y_values <- seq(0, 0.3, length.out = n_rows)
  
  my_color_palette <- c(
    "Combined All Features (1%)"          = "#6A3D9A",
    "Combined All Features (5%)"          = "#8B4513",
    "Combined Motif + Methylation (1%)"   = "#32CD32",
    "Combined Motif + Methylation + Ratios (1%)" = "#FFD700",
    "Combined Ratios + Methylation (1%)" = "#FF4500",
    "End Motifs"                          = "#E69F00",
    "Insert Size"                         = "#56B4E9",
    "Methylation"                         = "#CC79A7",
    "Nucleosome Peak"                     = "#0072B2",
    "Fragment Ratio"                      = "#009E73"
  )
  
  data_roc_plot <- val_data_roc_group2 %>%
    group_by(Metric, fpr) %>%
    summarise(tpr = mean(tpr, na.rm = TRUE),
              sd_tpr = mean(sd_tpr, na.rm = TRUE)) %>%
    ungroup()
  
  AUC_plot_group2 <- ggplot(data_roc_plot, aes(x = fpr, y = tpr, group = Metric, color = Metric)) +
    geom_line(aes(group = Metric), size = 1) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(data = val_data_auc_group2, 
              aes(x = 0.7, y = y_values, label = sprintf("%s = %.3f ± %.3f", Metric, mean_auc, sd_auc), color = Metric), 
              size = 2.5) +
    scale_color_manual(values = my_color_palette) +
    scale_fill_manual(values = my_color_palette) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curves with AUC Statistics") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = "none")
  
  CM_plot_group2 <- ggplot(val_data_cm_group2, aes(x = mean_sensitivity, y = mean_specificity, color = Metric)) +
    geom_point(size = 3) +
    geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_errorbarh(aes(
      xmin = pmax(0, mean_sensitivity - sd_sensitivity),
      xmax = pmin(1, mean_sensitivity + sd_sensitivity),
      y = mean_specificity), 
      height = 0.02, alpha = 0.7) +
    geom_errorbar(aes(
      ymin = pmax(0, mean_specificity - sd_specificity),
      ymax = pmin(1, mean_specificity + sd_specificity),
      x = mean_sensitivity), 
      width = 0.02, alpha = 0.7) +
    scale_color_manual(values = my_color_palette) +
    xlab("Sensitivity") +
    ylab("Specificity") +
    ggtitle("Performance") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = c(0.5, 0.21)) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    guides(color = guide_legend(ncol = 2))
  
  val_data_sens99_group2 <- val_data_sens99_group2 %>% arrange(desc(mean_sens99))
  val_data_sens99_group2$Metric <- factor(val_data_sens99_group2$Metric, levels = val_data_sens99_group2$Metric)
  
  sens99_plot_group2 <- ggplot(val_data_sens99_group2, aes(x = Metric, y = mean_sens99, fill = Metric)) +
    geom_bar(stat = "identity", width = 0.7, color = NA) +
    geom_errorbar(aes(ymin = mean_sens99 - sd_sens99, ymax = mean_sens99 + sd_sens99), width = 0.2) +
    scale_fill_manual(values = my_color_palette) +
    xlab("Method") +
    ylab("Sensitivity at 99% Specificity") +
    ggtitle("Sensitivity at 99% Specificity by Method") +
    scale_y_continuous(limits = c(0, 1)) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 13),
      axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      legend.position = "none",
      legend.key = element_rect(fill = "white"),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12),
      strip.background = element_blank(),
      strip.text = element_text(size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 13)
    )
  
  top_row_group2 <- ggarrange(AUC_plot_group2, CM_plot_group2, ncol = 2)
  final_fig_group2 <- annotate_figure(top_row_group2, top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group2)"), face = "bold", size = 14))
  
  ggsave(file.path(path, paste0("Sens99_plot_", type1, "_vs_", type2, "_Group2.pdf")), 
         sens99_plot_group2, width = 5, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group2.pdf")),
         final_fig_group2, width = 9, height = 5)
}

##############################
# (Optional) PRINT RESULTS FOR DEBUGGING
##############################
print("Group1 AUC:")
print(val_data_auc_group1)
print("Group2 AUC:")
print(val_data_auc_group2)
print("Group1 ROC data:")
print(val_data_roc_group1)
print("Group2 ROC data:")
print(val_data_roc_group2)
print("Group1 Confusion Metrics:")
print(val_data_cm_group1)
print("Group2 Confusion Metrics:")
print(val_data_cm_group2)
print("Group1 Sens99:")
print(val_data_sens99_group1)
print("Group2 Sens99:")
print(val_data_sens99_group2)


### Save 
saveRDS(val_data_auc_group1, file = "val_data_auc_group1.rds")
saveRDS(val_data_auc_group2, file = "val_data_auc_group2.rds")
saveRDS(val_data_roc_group1, file = "val_data_roc_group1.rds")
saveRDS(val_data_roc_group2, file = "val_data_roc_group2.rds")
saveRDS(val_data_cm_group1, file = "val_data_cm_group1.rds")
saveRDS(val_data_cm_group2, file = "val_data_cm_group2.rds")
saveRDS(val_data_sens99_group1, file = "val_data_sens99_group1.rds")
saveRDS(val_data_sens99_group2, file = "val_data_sens99_group2.rds")

write.csv(val_data_auc_group1, "val_data_auc_group1.csv", row.names = FALSE)
write.csv(val_data_auc_group2, "val_data_auc_group2.csv", row.names = FALSE)
write.csv(val_data_roc_group1, "val_data_roc_group1.csv", row.names = FALSE)
write.csv(val_data_roc_group2, "val_data_roc_group2.csv", row.names = FALSE)
write.csv(val_data_cm_group1, "val_data_cm_group1.csv", row.names = FALSE)
write.csv(val_data_cm_group2, "val_data_cm_group2.csv", row.names = FALSE)
write.csv(val_data_sens99_group1, "val_data_sens99_group1.csv", row.names = FALSE)
write.csv(val_data_sens99_group2, "val_data_sens99_group2.csv", row.names = FALSE)
write.csv(val_data_sens95_group1, "val_data_sens95_group1.csv", row.names = FALSE)
write.csv(val_data_sens90_group1, "val_data_sens90_group1.csv", row.names = FALSE)
write.csv(val_data_sens95_group2, "val_data_sens95_group2.csv", row.names = FALSE)
write.csv(val_data_sens90_group2, "val_data_sens90_group2.csv", row.names = FALSE)






##### Remake plots with and without legend 
# ---- Group1 Plots ----
{
  # Process AUC data for Group1
  val_data_auc_group1$mean_auc <- as.numeric(as.character(val_data_auc_group1$mean_auc))
  val_data_auc_group1 <- val_data_auc_group1[order(val_data_auc_group1$mean_auc), ]
  n_rows <- nrow(val_data_auc_group1)
  val_data_auc_group1$y_values <- seq(0, 0.3, length.out = n_rows)
  
  my_color_palette <- c(
    "Combined All Features (1%)"            = "#6A3D9A",
    "Combined All Features (5%)"            = "#8B4513",
    "Combined Motif + Methylation (1%)"       = "#32CD32",
    "Combined Motif + Methylation + Ratios (1%)" = "#FFD700",
    "Combined Ratios + Methylation (1%)"      = "#FF4500",
    "End Motifs"                            = "#E69F00",
    "Insert Size"                           = "#56B4E9",
    "Methylation"                           = "#CC79A7",
    "Nucleosome Peak"                       = "#0072B2",
    "Fragment Ratio"                        = "#009E73"
  )
  
  data_roc_plot <- val_data_roc_group1 %>%
    group_by(Metric, fpr) %>%
    summarise(tpr = mean(tpr, na.rm = TRUE),
              sd_tpr = mean(sd_tpr, na.rm = TRUE)) %>%
    ungroup()
  
  AUC_plot_group1 <- ggplot(data_roc_plot, aes(x = fpr, y = tpr, group = Metric, color = Metric)) +
    geom_line(size = 1) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(data = val_data_auc_group1, 
              aes(x = 0.7, y = y_values, label = sprintf("%s = %.3f ± %.3f", Metric, mean_auc, sd_auc), color = Metric), 
              size = 2.5) +
    scale_color_manual(values = my_color_palette) +
    scale_fill_manual(values = my_color_palette) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curves with AUC Statistics") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = "none")
  
  # ---- Create Two Versions of the CM Plot for Group1 ----
  # Base CM plot with legend
  CM_plot_group1_withlegend <- ggplot(val_data_cm_group1, aes(x = mean_sensitivity, y = mean_specificity, color = Metric)) +
    geom_point(size = 3) +
    geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_errorbarh(aes(
      xmin = pmax(0, mean_sensitivity - sd_sensitivity),
      xmax = pmin(1, mean_sensitivity + sd_sensitivity),
      y = mean_specificity), 
      height = 0.02, alpha = 0.7) +
    geom_errorbar(aes(
      ymin = pmax(0, mean_specificity - sd_specificity),
      ymax = pmin(1, mean_specificity + sd_specificity),
      x = mean_sensitivity), 
      width = 0.02, alpha = 0.7) +
    scale_color_manual(values = my_color_palette) +
    xlab("Sensitivity") +
    ylab("Specificity") +
    ggtitle("Performance") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = c(0.5, 0.21)) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    guides(color = guide_legend(ncol = 2))
  
  # CM plot version without legend
  CM_plot_group1_nolegend <- CM_plot_group1_withlegend + theme(legend.position = "none")
  
  # Sensitivity at 99% Specificity plot for Group1 remains unchanged
  val_data_sens99_group1 <- val_data_sens99_group1 %>% arrange(desc(mean_sens99))
  val_data_sens99_group1$Metric <- factor(val_data_sens99_group1$Metric, levels = val_data_sens99_group1$Metric)
  
  sens99_plot_group1 <- ggplot(val_data_sens99_group1, aes(x = Metric, y = mean_sens99, fill = Metric)) +
    geom_bar(stat = "identity", width = 0.7, color = NA) +
    geom_errorbar(aes(ymin = mean_sens99 - sd_sens99, ymax = mean_sens99 + sd_sens99), width = 0.2) +
    scale_fill_manual(values = my_color_palette) +
    xlab("Method") +
    ylab("Sensitivity at 99% Specificity") +
    ggtitle("Sensitivity at 99% Specificity by Method") +
    scale_y_continuous(limits = c(0, 1)) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 13),
      axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      legend.position = "none",
      legend.key = element_rect(fill = "white"),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12),
      strip.background = element_blank(),
      strip.text = element_text(size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 13)
    )
  
  # Arrange and annotate the top row for Group1 with both versions of the CM plot
  top_row_group1_withlegend <- ggarrange(AUC_plot_group1, CM_plot_group1_withlegend, ncol = 2)
  final_fig_group1_withlegend <- annotate_figure(top_row_group1_withlegend, 
                                                 top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group1)"), 
                                                                 face = "bold", size = 14))
  
  top_row_group1_nolegend <- ggarrange(AUC_plot_group1, CM_plot_group1_nolegend, ncol = 2)
  final_fig_group1_nolegend <- annotate_figure(top_row_group1_nolegend, 
                                               top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group1)"), 
                                                               face = "bold", size = 14))
  
  ggsave(file.path(path, paste0("Sens99_plot_", type1, "_vs_", type2, "_Group1.pdf")), 
         sens99_plot_group1, width = 5, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group1_withlegend.pdf")),
         final_fig_group1_withlegend, width = 9, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group1_nolegend.pdf")),
         final_fig_group1_nolegend, width = 9, height = 5)
}

# ---- Group2 Plots ----
{
  # Update Metric labels for Group2 to match the color scale
  unique_metrics_group2 <- unique(val_data_auc_group2$Metric)
  val_data_auc_group2$Metric <- factor(val_data_auc_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
  val_data_cm_group2$Metric <- factor(val_data_cm_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
  val_data_sens99_group2$Metric <- factor(val_data_sens99_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
  val_data_roc_group2$Metric <- factor(val_data_roc_group2$Metric, levels = unique_metrics_group2, labels = get_labels(unique_metrics_group2))
  
  val_data_auc_group2$mean_auc <- as.numeric(as.character(val_data_auc_group2$mean_auc))
  val_data_auc_group2 <- val_data_auc_group2[order(val_data_auc_group2$mean_auc), ]
  n_rows <- nrow(val_data_auc_group2)
  val_data_auc_group2$y_values <- seq(0, 0.3, length.out = n_rows)
  
  # Reuse the same color palette for consistency
  my_color_palette <- c(
    "Combined All Features (1%)"            = "#6A3D9A",
    "Combined All Features (5%)"            = "#8B4513",
    "Combined Motif + Methylation (1%)"       = "#32CD32",
    "Combined Motif + Methylation + Ratios (1%)" = "#FFD700",
    "Combined Ratios + Methylation (1%)"      = "#FF4500",
    "End Motifs"                            = "#E69F00",
    "Insert Size"                           = "#56B4E9",
    "Methylation"                           = "#CC79A7",
    "Nucleosome Peak"                       = "#0072B2",
    "Fragment Ratio"                        = "#009E73"
  )
  
  data_roc_plot <- val_data_roc_group2 %>%
    group_by(Metric, fpr) %>%
    summarise(tpr = mean(tpr, na.rm = TRUE),
              sd_tpr = mean(sd_tpr, na.rm = TRUE)) %>%
    ungroup()
  
  AUC_plot_group2 <- ggplot(data_roc_plot, aes(x = fpr, y = tpr, group = Metric, color = Metric)) +
    geom_line(size = 1) +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.5) +
    geom_text(data = val_data_auc_group2, 
              aes(x = 0.7, y = y_values, label = sprintf("%s = %.3f ± %.3f", Metric, mean_auc, sd_auc), color = Metric), 
              size = 2.5) +
    scale_color_manual(values = my_color_palette) +
    scale_fill_manual(values = my_color_palette) +
    xlab("False Positive Rate") +
    ylab("True Positive Rate") +
    ggtitle("ROC Curves with AUC Statistics") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = "none")
  
  # ---- Create Two Versions of the CM Plot for Group2 ----
  CM_plot_group2_withlegend <- ggplot(val_data_cm_group2, aes(x = mean_sensitivity, y = mean_specificity, color = Metric)) +
    geom_point(size = 3) +
    geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_vline(xintercept = 0.5, linetype = "dashed", color = "grey") +
    geom_errorbarh(aes(
      xmin = pmax(0, mean_sensitivity - sd_sensitivity),
      xmax = pmin(1, mean_sensitivity + sd_sensitivity),
      y = mean_specificity), 
      height = 0.02, alpha = 0.7) +
    geom_errorbar(aes(
      ymin = pmax(0, mean_specificity - sd_specificity),
      ymax = pmin(1, mean_specificity + sd_specificity),
      x = mean_sensitivity), 
      width = 0.02, alpha = 0.7) +
    scale_color_manual(values = my_color_palette) +
    xlab("Sensitivity") +
    ylab("Specificity") +
    ggtitle("Performance") +
    theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
          axis.line = element_line(colour = "black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          legend.title = element_text(size = 13),
          legend.key = element_rect(fill = "white"),
          legend.text = element_text(size = 6),
          legend.position = c(0.5, 0.21)) +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(limits = c(0, 1)) +
    guides(color = guide_legend(ncol = 2))
  
  CM_plot_group2_nolegend <- CM_plot_group2_withlegend + theme(legend.position = "none")
  
  val_data_sens99_group2 <- val_data_sens99_group2 %>% arrange(desc(mean_sens99))
  val_data_sens99_group2$Metric <- factor(val_data_sens99_group2$Metric, levels = val_data_sens99_group2$Metric)
  
  sens99_plot_group2 <- ggplot(val_data_sens99_group2, aes(x = Metric, y = mean_sens99, fill = Metric)) +
    geom_bar(stat = "identity", width = 0.7, color = NA) +
    geom_errorbar(aes(ymin = mean_sens99 - sd_sens99, ymax = mean_sens99 + sd_sens99), width = 0.2) +
    scale_fill_manual(values = my_color_palette) +
    xlab("Method") +
    ylab("Sensitivity at 99% Specificity") +
    ggtitle("Sensitivity at 99% Specificity by Method") +
    scale_y_continuous(limits = c(0, 1)) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 13),
      axis.line = element_line(colour = "black"),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      legend.position = "none",
      legend.key = element_rect(fill = "white"),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 12),
      strip.background = element_blank(),
      strip.text = element_text(size = 12),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 6),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 13)
    )
  
  top_row_group2_withlegend <- ggarrange(AUC_plot_group2, CM_plot_group2_withlegend, ncol = 2)
  final_fig_group2_withlegend <- annotate_figure(top_row_group2_withlegend, 
                                                 top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group2)"), 
                                                                 face = "bold", size = 14))
  
  top_row_group2_nolegend <- ggarrange(AUC_plot_group2, CM_plot_group2_nolegend, ncol = 2)
  final_fig_group2_nolegend <- annotate_figure(top_row_group2_nolegend, 
                                               top = text_grob(paste0(type1, " vs ", type2, " (Validation, Group2)"), 
                                                               face = "bold", size = 14))
  
  ggsave(file.path(path, paste0("Sens99_plot_", type1, "_vs_", type2, "_Group2.pdf")), 
         sens99_plot_group2, width = 5, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group2_withlegend.pdf")),
         final_fig_group2_withlegend, width = 9, height = 5)
  ggsave(file.path(path, paste0("classifier_performance_", type1, "_vs_", type2, "_Group2_nolegend.pdf")),
         final_fig_group2_nolegend, width = 9, height = 5)
}






#### Now make the plot with the kappa 
# Set the directory path
path <- "Final Data Dec 2024/ML_data/PE/Cancer_vs_normal/"

# List all files that match the pattern _results_healthy_vs_cancer.txt
file_list <- list.files(path, pattern = "_results_healthy_vs_cancer\\.txt$", full.names = TRUE)

# Initialize an empty data frame to store all results
results_df <- tibble()

# Loop over each file and read the data
for (file in file_list) {
  # Extract the feature name from the filename by removing the trailing pattern
  feature <- sub("_results_healthy_vs_cancer\\.txt$", "", basename(file))
  
  # Read the file (assuming tab-delimited with header)
  data <- read.table(file, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
  
  # Add the feature name as a new column
  data <- data %>% mutate(Feature = feature)
  
  # Append the data to the master data frame
  results_df <- bind_rows(results_df, data)
}

# Rename the 'test' column to 'Model' for clarity
results_df <- results_df %>% rename(Model = test)

# Recode model names to more descriptive names (adjust if needed)
results_df <- results_df %>%
  mutate(Model = recode(Model,
                        "LASSO" = "LASSO",
                        "LDA"   = "Linear Discriminant Analysis",
                        "KNN"   = "K-Nearest Neighbors",
                        "SVM"   = "Support Vector Machine",
                        "XGB"   = "XGBoost",
                        "GBM"   = "Gradient Boosting Machine",
                        "RF"    = "Random Forest"
  ))

# Optionally, reorder features (y-axis) by their maximum kappa value
feature_order <- results_df %>%
  group_by(Feature) %>%
  summarize(max_kappa = max(kappa, na.rm = TRUE)) %>%
  arrange(max_kappa) %>%
  pull(Feature)

results_df$Feature <- factor(results_df$Feature, levels = feature_order)

# Apply the helper function to change raw feature names to pretty labels
levels(results_df$Feature) <- get_labels(levels(results_df$Feature))

# Define a shared color palette for models
model_color_palette <- c(
  "LASSO"                     = "#66C2A5",  # teal
  "Linear Discriminant Analysis" = "#FC8D62",  # orange
  "K-Nearest Neighbors"       = "#8DA0CB",  # blue
  "Support Vector Machine"    = "#E78AC3",  # pink
  "XGBoost"                   = "#A6D854",  # green
  "Gradient Boosting Machine" = "#FFD92F",  # yellow
  "Random Forest"             = "#E5C494"   # beige
  # optionally add more if needed
)


# Build a Cleveland dot plot based on kappa
library(stringr)

kappa_plot <- ggplot(results_df, aes(x = kappa, y = Feature, color = Model)) +
  geom_point(size = 3, position = position_dodge(width = 0.7)) +
  geom_errorbarh(
    aes(xmin = pmax(0, kappa - error), xmax = pmin(1, kappa + error)),
    height = 0.2, position = position_dodge(width = 0.7)
  ) +
  labs(
    title = "Model Performance by Feature (Kappa)",
    x = "Kappa",
    y = "Feature",
    color = "Model"
  ) +
  scale_color_manual(values = model_color_palette) +
  guides(color = guide_legend(nrow = 3, byrow = TRUE)) +
  # Wrap labels so they use multiple lines
  scale_y_discrete(labels = function(x) str_wrap(x, width = 20)) +
  theme_classic(base_size = 14) +
  theme(
    plot.title      = element_text(hjust = 0.5, face = "bold", size = 16),
    axis.text.y     = element_text(size = 10),
    axis.text.x     = element_text(size = 10),
    axis.title      = element_text(size = 12),
    legend.position = "bottom",
    legend.title    = element_text(size = 12),
    legend.text     = element_text(size = 10)
  )


# Save the plot as a PNG file
ggsave("ClevelandPlot_Models_Kappa_CN_classifier_PE.png", kappa_plot, width = 8, height = 12, dpi = 500)

# Print the plot to the graphics device
print(kappa_plot)

write.csv(results_df, "Kappas_PE_data_CN_classifier.csv", row.names = FALSE)

